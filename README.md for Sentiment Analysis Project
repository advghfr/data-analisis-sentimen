A tutorial on scraping Twitter data using Twint, cleaning the text, and classifying tweets into positive, negative, and neutral categories.
The comparison between VADER and Lexicon-Based (Bing Liu) methods shows good consistency in sentiment polarity, proving that lexicon testing strengthens rule-based sentiment analysis

âš™ï¸ Technologies Used
1. Python
2. JupyterLab / Jupyter Notebook

Libraries:
1. twint â€“ Scraping Twitter data
2. vaderSentiment â€“ Automatic sentiment labeling
3. nltk, pandas â€“ Text processing & data analysis
4. matplotlib â€“ Visualization

ğŸ§© Workflow
1. Scrape tweets using Twint
2. Clean and preprocess text (tokenize, remove stopwords, stemming, lemmatization)
3. Classify tweets using VADER
4. Validate results with Lexicon-Based (Bing Liu)
5. Visualize sentiment distribution

ğŸ§  Objectives
1. To analyze public sentiment on the Papua armed conflict through Twitter
2. To demonstrate sentiment analysis using VADER and Lexicon-Based methods
3. To compare and evaluate sentiment consistency between both approaches

ğŸ“ Dataset

Source: Tweets with hashtag #KKBPAPUA
Total: 433 tweets
Format: CSV after preprocessing

Licensed under the Apache License 2.0
Â© 2022 Adiev Ghifari Syahviar. All rights reserved under applicable patent and copyright law.
